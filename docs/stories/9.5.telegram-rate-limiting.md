# Story 9.5: Telegram Rate‑Limiting & Delivery Reliability

## Status
Ready for Review

## Story
As a developer, I need a reliable messaging subsystem that respects Telegram rate limits and provides retries and observability so global statements and ad‑hoc sends are robust at scale.

## Acceptance Criteria

- [ ] Global throughput control
  - Token bucket with configurable capacity (default 15 msg/sec)
  - Burst allowance up to capacity, steady refill per second
- [ ] Per‑chat throttle
  - Max 1 message per second per `chat_id`
- [ ] 429 handling
  - Detect `Too Many Requests` responses and read `retry_after`
  - Pause sending for specified duration (global and/or chat scope) and retry
- [ ] Retry policy
  - Exponential backoff with jitter for 5xx and network timeouts
  - Max 3 retries before marking failed
- [ ] Idempotency
  - Prevent duplicate sends on retries (dedupe by chat_id + hash(message) within run)
- [ ] Observability
  - Structured logs: chat_id, message_hash, attempt, latency_ms, outcome
  - Summary metrics: sent, retried, failed
  - Optional debug mode to dry‑run without sending

## Tasks / Subtasks

- [x] Implement `MessagingQueue` abstraction wrapping Telegram send API
- [x] Add counters and structured logging
- [x] Provide configuration via env (`TELEGRAM_MAX_RPS`, `TELEGRAM_PER_CHAT_RPS`)
- [x] Unit tests covering throttling and retry paths

## Dev Notes

- Keep API adapter small; integrate with existing `telegram_bot.Application` when available, otherwise call HTTPS Bot API directly with `requests`/`httpx`
- Prefer asyncio for concurrency; isolate rate limiters as awaitable gates

## Dev Agent Record

- Agent Model Used: gpt-5-codex
- Debug Log References:
  - `pytest tests/unit/test_daily_statement_service.py tests/unit/test_telegram_messaging_queue.py`
- Completion Notes:
  - Built `MessagingQueue` with configurable token bucket, per-chat throttles, 429 awareness, dedupe-by-hash, metrics, and optional dry-run support while allowing any send callable.
  - Rewired `DailyStatementSender` to reuse the queue, simplifying logging/cleanup and offloading all rate limit/retry logic to the new abstraction.
  - Propagated the new env knobs into `Config`/`.env.example` and added focused unit tests covering both the queue throttling paths and the statement sender's integration.
- File List:
  - `src/services/telegram_messaging_queue.py`
  - `src/services/daily_statement_service.py`
  - `src/core/config.py`
  - `.env.example`
  - `tests/unit/test_daily_statement_service.py`
  - `tests/unit/test_telegram_messaging_queue.py`
  - `docs/stories/9.5.telegram-rate-limiting.md`
- Change Log:
  - Introduced `MessagingQueue` to encapsulate Telegram rate limiting, retries, backoff, dedup, metrics, and observability.
  - Updated the daily statement sender to rely on the queue and emit structured failure/success records plus new config-driven defaults.
  - Added unit tests exercising the queue's throttle/retry behavior and refreshed story metadata to mark the work as ready for review.
