# Story 9.5: Telegram Rate‑Limiting & Delivery Reliability

## Status
Approved

## Story
As a developer, I need a reliable messaging subsystem that respects Telegram rate limits and provides retries and observability so global statements and ad‑hoc sends are robust at scale.

## Acceptance Criteria

- [ ] Global throughput control
  - Token bucket with configurable capacity (default 15 msg/sec)
  - Burst allowance up to capacity, steady refill per second
- [ ] Per‑chat throttle
  - Max 1 message per second per `chat_id`
- [ ] 429 handling
  - Detect `Too Many Requests` responses and read `retry_after`
  - Pause sending for specified duration (global and/or chat scope) and retry
- [ ] Retry policy
  - Exponential backoff with jitter for 5xx and network timeouts
  - Max 3 retries before marking failed
- [ ] Idempotency
  - Prevent duplicate sends on retries (dedupe by chat_id + hash(message) within run)
- [ ] Observability
  - Structured logs: chat_id, message_hash, attempt, latency_ms, outcome
  - Summary metrics: sent, retried, failed
  - Optional debug mode to dry‑run without sending

## Tasks / Subtasks

- [ ] Implement `MessagingQueue` abstraction wrapping Telegram send API
- [ ] Add counters and structured logging
- [ ] Provide configuration via env (`TELEGRAM_MAX_RPS`, `TELEGRAM_PER_CHAT_RPS`)
- [ ] Unit tests covering throttling and retry paths

## Dev Notes

- Keep API adapter small; integrate with existing `telegram_bot.Application` when available, otherwise call HTTPS Bot API directly with `requests`/`httpx`
- Prefer asyncio for concurrency; isolate rate limiters as awaitable gates

